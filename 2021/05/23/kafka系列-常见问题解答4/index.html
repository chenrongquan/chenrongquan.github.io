<!DOCTYPE html>
<html>
  <head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport">
  <meta name="description" content="quan&#39;s blog">
  <meta name="keyword" content="hexo-theme, vuejs">
  
    <link rel="shortcut icon" type="image/ico" href="/css/images/logo.png"/>
  
  <title>
     
      kafka系列 | 常见问题解答(4) | ™技术博客 
    
  </title>
  <link href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">
  <link href="//cdnjs.cloudflare.com/ajax/libs/nprogress/0.2.0/nprogress.min.css" rel="stylesheet">
  <link href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/tomorrow.min.css" rel="stylesheet">
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/css/plugins/gitment.css">

  
  <script src="//cdnjs.cloudflare.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/geopattern/1.2.3/js/geopattern.min.js"></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/nprogress/0.2.0/nprogress.min.js"></script>
  
    
<script src="/js/qrious.js"></script>

  
  
    
<script src="/js/gitment.js"></script>

  
  
  
    <!-- MathJax support START -->
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <!-- MathJax support END -->
  


  
<meta name="generator" content="Hexo 5.3.0"></head>
<div class="wechat-share">
  <img src="/css/images/logo.png" />
</div>
  <body>
    <header class="header fixed-header">
  <div class="header-container">
    <a class="home-link" href="/">
      <div class="logo"></div>
      <span>™技术博客</span>
    </a>
    <ul class="right-list">
      
        <li class="list-item">
          
            <a href="/" class="item-link">主页</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/tags/" class="item-link">标签</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/archives/" class="item-link">归档</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/project/" class="item-link">项目</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/about/" class="item-link">关于</a>
          
        </li>
      
    </ul>
    <div class="menu">
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </div>
    <div class="menu-mask">
      <ul class="menu-list">
        
          <li class="menu-item">
            
              <a href="/" class="menu-link">主页</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/tags/" class="menu-link">标签</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/archives/" class="menu-link">归档</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/project/" class="menu-link">项目</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/about/" class="menu-link">关于</a>
            
          </li>
        
      </ul>
    </div>
  </div>
</header>
    <div id="article-banner">
  <h2>kafka系列 | 常见问题解答(4)</h2>
  <p class="post-date">2021年5月23日</p>
  <div class="arrow-down">
    <a href="javascript:;"></a>
  </div>
</div>
<main class="app-body flex-box">
  <!-- Article START -->
  <article class="post-article">
    <section class="markdown-content"><ol>
<li>advertised.listener和listener这两个参数，具体有什么区别</li>
</ol>
<ul>
<li>advertised.listener主要是给通过外网访问的clients使用的。如果你的clients都是通过内网访问Kafka，只设置listeners就可以了。</li>
<li>它们可以同时设置，常见的做法是设置advertised.listener为公网IP，listeners为内网IP，区分开来</li>
</ul>
<ol start="2">
<li>listeners属性是指定该broker的ip和端口的对吧？</li>
</ol>
<ul>
<li>对。&lt;host, port&gt;对</li>
</ul>
<ol start="3">
<li>log.segment.bytes参数？</li>
</ol>
<ul>
<li>log.segment.bytes是控制日志段文件的最大尺寸。</li>
<li>可以认为一个日志段文件里面包含了成千上万条的消息。</li>
</ul>
<ol start="4">
<li>zookeeper.connect的chroot这个点没有看懂，两套kafka集群不应该是每套都单独有自己的配置文件吗？kafka1和kafka2这2个别名在哪里设置的呢</li>
</ol>
<ul>
<li>是有独立的配置文件。这里的chroot设置是指在ZooKeeper中使用独立的znode父节点。</li>
</ul>
<ol start="5">
<li>unclean.leader.election.enable 设置为false表示落后太多进度的副本无法没有资格做完leader，落后的进度多少算多呢？这个也是可以配置的吗？</li>
</ol>
<ul>
<li>由replica.lag.time.max.ms控制。</li>
</ul>
<ol start="6">
<li>消费者处理消息如果时间过长的话，会长期阻塞在poll方法上，无法继续消费新的消息</li>
</ol>
<ul>
<li>“消费者处理消息如果时间过长” 为什么会阻塞在poll方法上呢？应该是阻塞在处理方法中吧？</li>
<li>一个可能的原因是处理时间过长导致的频繁rebalance。看看日志是否存在频繁rebalance的情况。</li>
</ul>
<ol start="7">
<li>log.dirs 配置多个多路径后，具体是怎样提高读写性能的？</li>
</ol>
<ul>
<li>多个路径，多个线程同时加载，加速</li>
</ul>
<ol start="8">
<li>message.max.bytes 设置broker 和 client 各有一份，如果client 发送超过设定大小的msg ，broker的处理方式是怎样的？</li>
</ol>
<ul>
<li> broker端会抛出异常</li>
</ul>
<ol start="9">
<li>zk1:2181,zk2:2181,zk3:2181/kafka1，zk1:2181,zk2:2181,zk3:2181/kafka2 中的 kafka1 和 kafka2 这2个别名需要设置吗？如果需要配置，在哪里配置参数是什么？</li>
</ol>
<ul>
<li>这是ZooKeeper上的chroot配置。如果你的ZooKeeper只服务于一套Kafka集群，那么可以不配置这个参数</li>
<li>否则就要设置chroot以区分要服务的不同Kafka集群。配置方法就是在listeners中直接指定就行了</li>
</ul>
<ol start="10">
<li>kafka保存偏移量好像是在zookeeper，不是在kafka;请问哪个版本之后是存在kafka的？</li>
</ol>
<ul>
<li>0.9提供的java consumer之后已经不把offset保存在ZooKeeper中了</li>
</ul>
<ol start="11">
<li>若auto.leader.rebalance.enable=false，当集群 leader 不均匀的时候，执行kafka-preferred-replica-election.sh 脚本来重新平衡集群中的leader副本对集群会有什么影响，对消费者和生产者客户端有何影响？是否会造成消息丢失？应该如何更好地应对？尤其是如何保障避免消息丢失？</li>
</ol>
<ul>
<li>auto.leader.rebalance.enable=false只是关闭自动调整机制。手动运行这个命令对所有副本执行preferred leader election是有风险的，因为可能涉及到大量分区的leader变更，会瞬间推高consumer和producer的请求延时，降低TPS。</li>
<li>至于消息丢失，我觉得倒是不会。建议是尽量在低峰时刻执行这类操作。</li>
</ul>
<ol start="12">
<li>listeners设置协议用PLAINTEXT，advertised.listeners设置协议为SASL_PLAINTEXT，让broker之间走plaintext，这样内部相互传输快些，但是外部访问则需要认证</li>
</ol>
<ul>
<li> 这是可以的，broker间的网络通讯是安全的话其实没必要做SSL</li>
</ul>
<ol start="13">
<li>kafka的log存储目录可以指定为hdfs上么，如果可以，那就不用给分区指定副本了，因为hdfs默认就是三个副本</li>
</ol>
<ul>
<li>目前不可以</li>
</ul>
<ol start="14">
<li>请问num.partitions个数一般建议设置为多少个，是和broker的个数一致吗？提高partitions的个数，能增加消费者的消费速度吗？</li>
</ol>
<ul>
<li>num.partitions是自动创建topic的分区数。其实我觉得运维良好的集群应该禁掉自动创建topic，所有topic全部有运维手动创建好。所以理论上这个参数应该用不上。</li>
<li>不过你的问题和如何评估分区数是相同的，基本上要结合你的SLA加上性能测试来共同决定。</li>
</ul>
<ol start="15">
<li>“坏掉的磁盘上的数据会自动地转移到其他正常的磁盘上，而且 Broker 还能正常工作。”磁盘都坏啦，还能转移？</li>
</ol>
<ul>
<li>等恢复了再转移</li>
</ul>
<ol start="16">
<li>unclean.leader.election.enable 设置为false, 并且最后导致了分区不能用，那么该分区中的数据消费者也消费不到了，相当于数据丢失了，那么有什么办法能继续消费该分区数据吗？</li>
</ol>
<ul>
<li>没办法。分区不可用之后里面的数据无法消费。hmmm，这种情况也不算数据丢失了，因为只要分区恢复正常，还是可以继续消费的</li>
</ul>
<ol start="17">
<li> log.dirs这个参数目的是将【某一个】broker的数据分散的存储到不同的目录或磁盘下。在之后设置了分区、副本策略后，多分区多副本的数据可能存储在不同的目录/磁盘下，但都是属于这个broker的。</li>
</ol>
<ol start="18">
<li> log.retention.bytes，这个参数控制的是broker级别的删除吗。一个broker会存储属于不同topic的副本，如果某个broker因为达到容量上限了，触发策略删除了此broker中的旧日志段，这样不就导致该broker上副本的数据和其他broker上同topic的副本数据不一致了吗。还是说只会删除leader副本的日志段。</li>
</ol>
<ul>
<li>log.retention.bytes是broker级别的参数，但是具体生效的范围是单个分区日志。另外在删除的时候要对HW与删除位移上限的比较。如果后者越过了HW自然不允许删除该日志段</li>
</ul>
<ol start="19">
<li>参数delete.topic.enable？</li>
</ol>
<ul>
<li>建议delete.topic.enable保持默认值true就好，毕竟不能删除topic总显得不太方便。只是要注意权限设置即可，不可能 让任何人都能有删除topic的权限。</li>
</ul>
<ol start="20">
<li>对于磁盘坏掉以后转移到其他磁盘的机制，我有点疑问，如果已经坏掉，则不可读了，那么是不是只能从副本去转移了，如果从副本转移那就有可能会丢失部分最新的数据吧？</li>
</ol>
<ul>
<li>broker会重建副本，然后走正常的同步机制：从leader处拉取数据。</li>
</ul>
<ol start="21">
<li>auto.leader.rebalance.enable 这个值设置为true，那么您说的定期重新选举，应该有个触发的条件吧？我刚才跟同事沟通过，他说是跟每台broker的leader数量有关，如果leader分布不均衡就会触发重新选举leader，但是感觉说的还是不够具体，您能给解答下吗，感谢</li>
</ol>
<ul>
<li>的确是有个比例，要超过这个比例才会触发preferred leader选举。这个比例由broker端参数leader.imbalance.per.broker.percentage控制，默认是10%。</li>
<li>举个例子，如果一个broker上有10个分区，有2个分区的leader不是preferred leader，那么就会触发</li>
</ul>
<ol start="22">
<li>就是1.1版本之前，如果Kafka使用的任何一块硬盘坏掉了，Broker就会宕机。1.1版本之后不会了~</li>
</ol>
<ol start="23">
<li>坏掉的磁盘上的数据会自动地转移到其他正常的磁盘上，而且 Broker 还能正常工作’kafka如何做到坏掉的磁盘上的数据自动转移到其他正常的磁盘上的？</li>
</ol>
<ul>
<li>可能表述的有点歧义。这里是说当出现坏盘后Broker进程依然可以为好盘正常提供服务。一旦用户触发了reassign，Kafka支持将坏掉磁盘上的数据自动地转移到其他正常的磁盘上。</li>
</ul>
<ol start="24">
<li>如果磁盘坏掉了，这些数据是什么机制读取到其他磁盘上的呢？不是都坏了吗？不应该读取其他副本中的数据了吗？这个磁盘上的数据就算是丢失了吗？</li>
</ol>
<ul>
<li>Broker会在好的目录上重建副本。另外Kafka也提供了工具将某块磁盘上的数据直接搬移到另一个磁盘上，毕竟磁盘坏了也不是不能修好</li>
</ul>
<ol start="25">
<li>如果unclean.leader.election.enable这个参数设置为false，一个partition挂了，不让数据少的副本参与选举，那么不就会一直没有副本了吗？我还有个问题，在磁盘满的情况我的一个topic其中的一个partition-0对应的brokerid变成了-1，本来是100的（手动设置的100,-1不知道怎么变的），那么这个partition-0就就找不到这个broker，导致无法进行消费。</li>
</ol>
<ul>
<li>如果ISR为空，unclean.leader.election.enable=false，当leader挂了的时候分区就不可用了。</li>
<li>100是broker id，-1表示没有leader了，原因就是100的broker磁盘满了宕机了，正常情况下leader应该会切换到其他的副本上，除非你的副本数就是1</li>
</ul>
<ol start="26">
<li>每个partition的副本保存的数据不是应该和leader是一模一样的吗？为什么会有丢失的？</li>
</ol>
<ul>
<li>它们是异步拉取消息的，必然有一个时间窗口导致它和leader中的数据是不一致的，或者说它是落后于leader的。</li>
</ul>
<ol start="26">
<li>对于failover机制，kafka会新建副本，从leader处同步最新的数据给新建副本。如果坏掉的盘是leader持久化的盘呢？</li>
</ol>
<ul>
<li>那就先选举新的leader。</li>
</ul>
<ol start="27">
<li>请问unclean.leader.election.enable设置为false之后，如果leader副本挂掉了那这个分区就无法使用了，是不是意味数据会丢失呢？</li>
</ol>
<ul>
<li>leader挂掉了Kafka会从ISR剩下的副本中选择一个当leader，但如果ISR也没有副本了，leader就选不出来了。</li>
<li>如果设置unclean.leader.election.enable=true，则允许Kafka从那些不在ISR但依然存活的副本中选择一个出来当leader。此时是有数据丢失的风险的</li>
</ul>
<ol start="28">
<li>message.max.bytes设置后是不是影响了kafka的内存占用大小？</li>
</ol>
<ul>
<li>对于普通的消息处理，这个值不会增加额外的内存占用，它不像是数组的长度那样 ，即使用不完也要申请足量的内存空间。</li>
<li>但对于Log Cleaner而言（就是为topic执行compact操作的线程），这个值的确会占用更多的内存，因为cleaner的读写buffer都要申请一块ByteBuffer。这个值越大这块buffer也就越大。好在cleaner thread也就那么几个。</li>
</ul>
<ol start="27">
<li>消息队列重复消费问题有什么太好的办法吗？我们现在的做法是把offset和消费后的计算结果一并保存在业务系统中，有没有更好的做法</li>
</ol>
<ul>
<li>试试Kafka 0.11引入的事务</li>
</ul>
<ol start="28">
<li>假如现有集群已经有3个分区，动态添加两个分区, 原有的分区会迁移数据到新增的分区吗？</li>
</ol>
<ul>
<li>不会。已有数据将一直“躺在”原有分区中。</li>
</ul>
<ol start="29">
<li>“坚决不能让那些落后太多的副本竞选 Leader”，请问落后多少算是太多呢？</li>
</ol>
<ul>
<li>这个取决于broker端参数replica.lag.time.max.ms的取值</li>
</ul>
<ol start="30">
<li>坏掉的数据是怎么自动转移到其他磁盘上的呢？</li>
</ol>
<ul>
<li>Broker自动在好的路径上重建副本，然后从leader同步；</li>
<li> Kafka支持工具能够将某个路径上的数据拷贝到其他路径上</li>
</ul>
<ol start="31">
<li>如果坏掉的盘是leader持久化的盘并且其他副本没有来的及从坏掉的leader分区同步最新数据，重新选举leader后岂不是也会丢失数据？？？</li>
</ol>
<ul>
<li> 是的，这种情况会丢失数据。其实Kafka并没有承诺不丢失数据，而是在满足某些条件下才做持久化保证。</li>
</ul>
<ol start="32">
<li>Kafka舍弃了分区容忍性这一点是否可以体现在社区默认将Unclean设置为false上呢？</li>
</ol>
<ul>
<li>Kafka是依托于ZooKeeper以及合理配置minIsr等参数来规避脑裂的。</li>
<li>变更为false就是很朴素的思想：用户在默认情况下可能更加关心数据一致性，不想数据丢失。如果用户想要更高的可用性，手动调整即可。</li>
</ul>
<ol start="33">
<li>把message.max.bytes设置地挺大，但是java生产者发送1M以上数据就失败，集群也重启过，版本0.10左右 是否有其他参数需要调？</li>
</ol>
<ul>
<li> 需要。producer、broker、consumer三端都需要调整</li>
<li> broker: message.max.bytes和replica.fetch.max.bytes</li>
<li> consumer：fetch.message.max.bytes</li>
</ul>
<ol start="34">
<li>log.retention.bytes这个参数是针对主题的吧？比如设置为100M，Kafka定期会把每个主题的日志数据留存到100M以下？</li>
</ol>
<ul>
<li>这个参数既有broker端也有topic端，不过最终都是作用于topic的。</li>
<li>另外算法上也不是简单的比较大小。</li>
<li>举个例子吧：假设日志段大小是700MB，当前分区共有4个日志段文件，大小分别是700MB，700MB，700MB和1234B;显然1234B那个文件就是active日志段。此时该分区总的日志大小是3*700MB+1234B=2100MB+1234B，如果阈值设置为2000MB，那么超出阈值的部分就是100MB+1234B，小于日志段大小700MB，故Kafka不会执行任何删除操作，即使总大小已经超过了阈值；反之如果阈值设置为1400MB，那么超过阈值的部分就是700MB+1234B &gt; 700MB，此时Kafka会删除最老的那个日志段文件</li>
</ul>
<ol start="35">
<li>auto.offset.reset，我有时候删除一个topic时会导致offset异常，出现重复消费问题，不知道跟这个参数有没有关系？？</li>
</ol>
<ul>
<li>当consumer启动后它会从Kafka读取它上次消费的位移。</li>
<li>情况1： 如果 Kafka broker端没有保存这个位移值，那么consumer会看auto.offset.reset的脸色</li>
<li>情况2：consumer拿到位移值开始消费，如果后面发现它要读取消息的位移在Kafka中不存在（可能对应的消息已经被删除了），那么它也会看auto.offset.reset的脸色</li>
<li>情况3：除以上这两种情况之外consumer不会再顾忌auto.offset.reset的值</li>
<li>怎么看auto.offset.reset的脸色呢？简单说就是earliest从头消息；latest从当前新位移处消费。</li>
</ul>
<ol start="36">
<li> advertised.listeners 这个配置能否再解释一下。感觉配置了 listeners之后就不用配置这个了呀？</li>
</ol>
<ul>
<li> advertised.listeners主要是为外网访问用的。如果clients在内网环境访问Kafka不需要配置这个参数。</li>
<li> 常见的玩法是：你的Kafka Broker机器上配置了双网卡，一块网卡用于内网访问（即我们常说的内网IP）；另一个块用于外网访问。那么你可以配置listeners为内网IP，advertised.listeners为外网IP。</li>
</ul>
<ol start="37">
<li>生产环境有个__counsumer_offsets-49目录经常会变的很大，把磁盘撑满，要设置什么参数优化一下啊？手工清理__counsumer_offsets-49目录下的文件有什么影响吗？</li>
</ol>
<ul>
<li>要确定是不是bug，目前这个topic占用磁盘空间过多的问题社区有几个bug，最好去搜搜看。另外用jstack查一下log cleaner线程的状态。最后调优的话就是适当增加log.cleaner.threads的值，前提是你的log cleaner线程是正常工作的</li>
<li>手动清理可能会造成部分consumer group的位移提交数据丢失</li>
</ul>
<ol start="38">
<li>在用kafka-topic.sh和group相关的命令时候，我发现可以用–bootstrap-server指定kafka来跑命令，也可以用 –zookeeper 指定zk来跑命令，这两种执行的方式有什么区别吗</li>
</ol>
<ul>
<li>–zookeeper已经被标记为“不推荐”了，后续可能会被移除。对于用户来说，这两个参数没有太大区别</li>
</ul>
<ol start="39">
<li>写入pagecache如果数据丢失了，就真丢失了吧。。冗余机制毕竟只是从leader拿数据，写不到leader的数据不就真丢失了吗</li>
</ol>
<ul>
<li>所以靠软件层面来保证不丢失。比如多个follower + acks=all</li>
</ul>
<ol start="40">
<li>kafka高性能的原因是因为顺序读写，但是一旦删除数据，会不会造成磁盘的碎片化，导致新的写入的数据，就不是顺序读写了？</li>
</ol>
<ul>
<li>Kafka的写入都是追加写(append-only)，所以是可以保证顺序写入的。删除数据是从文件起始部分开始删除，不影响写入。</li>
<li>真正影响顺写写入的因素是同时写入多个分区的数据，此时，确实很难保证顺序写入</li>
</ul>
<ol start="41">
<li>如果kafka在删除的时候，是不是一定会规避这些正在消费的数据，如果不规避会产生什么问题？二是，我们常遇到协调者死掉的问题，这个有可能有什么原因引起的。我们在用的版本为apache kafka0.10.1</li>
</ol>
<ul>
<li>删除的时候不会顾及consumer的。可能的问题就是位移越界导致的位移重置，比如consumer位移发生跳跃的情形</li>
<li> 是Coordinator挂掉还是所在broker挂掉？或者说后者挂掉也不一定就是Coordinator组件故障导致的吧。最好还是给出一些详细信息，否则不太好评估。</li>
</ul>
<ol start="42">
<li>如果你只有8GB，就不要设置6GB了，酌情调小吧。具体设置方法可以监控堆上的live data，然后大约乘以1.5或2即可。比如你可以手动触发Full GC，然后查看一下堆上存活的数据大小，比如说是1500MB，那么你可以设置heap size为2.25GB。</li>
</ol>
<ol start="43">
<li>retention.ms/retention.bytes 这两个参数是不是只要满足一个，Kafka就会开始清消息了？还是需要两个同时满足才会清消息？</li>
</ol>
<ul>
<li>满足任何一个就会开始删除消息</li>
</ul>
<ol start="44">
<li>参数retention.bytes应该是指使用的磁盘空间吧，而且是针对于单个分区的;之前遇到过kafka将磁盘写满的情况，导致broker不可用，请问有什么好的预防措施和监控手段么？</li>
</ol>
<ul>
<li>这是topic级别的参数，控制每个分区能占用的最大磁盘空间。设置它就好了~~</li>
<li>监控的话，好像没有现成的JMX指标。我之前写过一个方法可以监控磁盘占用，你不妨一试：<a target="_blank" rel="noopener" href="https://www.cnblogs.com/huxi2b/p/7929690.html">https://www.cnblogs.com/huxi2b/p/7929690.html</a></li>
</ul>
<ol start="45">
<li><p>监控堆占用也是sizing的一个好办法，特别是监控Full GC之后的live data大小。</p>
</li>
<li><p>文章中提到的JVM版本问题，是否有比较好的建议呢？Java版本对于Kafka的性能方面影响大吗？</p>
</li>
</ol>
<ul>
<li>Kafka 2.0已经不支持Java 7了，2.1版本开始初步支持Java 11，但不建议生产环境用11，所以还是使用Java 8吧。</li>
<li>性能方面，如果是Linux平台，性能的差异主要还是Java版本升级带来的差异吧，应该说影响不是太大。</li>
</ul>
<ol start="46">
<li>老师请教一个问题，我们设置了过期时间3小时，但是客户端还是会消费到昨天的昨天的消息，这个如何查找原因呢</li>
</ol>
<ul>
<li>你要有多个日志段文件消息删除才可能生效。只有一个日志段文件是没用的。</li>
<li>路径下有多个.log文件才有可能删除消息，如果只有一个.log文件是不会开启的，即使满足条件也不行。</li>
</ul>
<ol start="47">
<li>broker的本质是什么？启动一个kafka应用程序的进程就相当于一个broker在跑了嘛？还是说可以通过设置会存在多个broker在跑？broker和topic的关系是怎么样的？目前我确定的是一个kafka集群中topic一定是一个唯一的，但肯定会有多个broker，是不是说启一台kafka服务器就是一个broker在跑，多个一块构成一个集群？还是说一台服务器可以跑多个kafka程序也有多个broker在跑，也能构成一个集群，只是比较脆弱？分区的底层数据结构是什么？队列？数组还是列表？还是说分区这一次还不够底层和具体的数据结构关系不大？</li>
</ol>
<ul>
<li>Broker是Kafka集群的服务器。启动集群就是指启动若干个Broker进程</li>
<li>Topic在一个Kafka集群上可能有很多个，Topic数据的确保存在Broker上，但它们之间没有什么关系。1台Broker也可以对外提供服务，只是如你所说：很脆弱。</li>
<li>分区下面是副本，副本的存储结构是日志（log）。每条消息写入分区时，其实是写入副本的日志文件中</li>
</ul>
<ol start="48">
<li> broker list 这个参数，在我的集群有三个broker 的情况下，我发现 只填一个 和 三个都填上 都可以用，这个有什么区别吗？</li>
</ol>
<ul>
<li>确实只需要写1个就可以，因为Kafka能够通过这1个找到集群所有的Broker。当然最好还是多写几个</li>
</ul>
<ol start="49">
<li>，如果swap=0，内存不足时oom killer触发可能直接将broker进程杀死。而如果设置swap为一个比较小的值，在oom killer触发前你至少有一段时间观察到broker性能变差，给你监控和调优都留了一些时间</li>
</ol>
<ol start="50">
<li>kafka消费段，过一段时间jvm内存就会超过设置上线，有什么好的思路调整吗</li>
</ol>
<ul>
<li>OOM的问题首先看下到底是那OOM的问题可以这样排查：<ul>
<li>到底是哪部分内存。大部分是堆溢出</li>
<li> 如果是heap溢出，主要看stacktrace，看看到底是哪段代码导致的</li>
<li> 再看导致的原因，到底是内存泄露还是内存溢出。这两者是有区别的。前者是程序写的有问题，后者是程序确实需要这么多内存，那么只能增加heap size</li>
<li> 不管怎么样，你可以先增加一下heap size试试，如果还是OOM，那么很有可能出现了内存泄露</li>
</ul>
</li>
</ul>
<ol start="51">
<li>系统会根据LRU算法定期将页缓存上的 脏 数据落盘到物理磁盘上. 这个定期就是由提交时间来确定的,默认是5秒.这个时间如何设置？ 是内核参数吗？</li>
</ol>
<ul>
<li>不算内核参数，是文件系统的参数。你可以查询一下文件系统手册。比如ext4就是commit=Nseconds这样设置</li>
</ul>
<ol start="52">
<li>怎么能限制消费者的消费速度，或者限制消费带宽啊，</li>
</ol>
<ul>
<li>这是我之前写的，可以参考下：<a target="_blank" rel="noopener" href="https://www.cnblogs.com/huxi2b/p/8609453.html">https://www.cnblogs.com/huxi2b/p/8609453.html</a></li>
</ul>
<ol start="53">
<li>写入到pageCache 根据配置的时间‘脏数据’Flush到磁盘，kafka 把数据同步到磁盘只在这个地方做吗。意思是：只有每次‘判断’的脏数据才入盘吗，其他的数据呢？</li>
</ol>
<ul>
<li>Kafka其实只是把数据写入到pagecache中，后面的刷盘是由os完成的，什么时候刷，刷那些数据都是由os决定</li>
</ul>
<ol start="54">
<li>如何评判堆内存大小设置的标准。</li>
</ol>
<ul>
<li>没有通用的标准，只有一个最佳实践值：6GB。</li>
<li>最好还是监控一下实时的堆大小，特别是GC之后的live data大小，通常将heapsize设置成其1.5~2倍就足以了</li>
</ul>
<ol start="55">
<li>页缓存它存在的意义和作用，以及它在整个过程中的机制又是怎样的呢？</li>
</ol>
<ul>
<li>页缓存属于磁盘缓存（Disk cache）的一种，主要是为了改善系统性能。重复访问磁盘上的磁盘块是常见的操作，把它们保存在内存中可以避免昂贵的磁盘IO操作。</li>
<li>既然叫页缓存，它是根据页（page）来组织的内存结构。每一页包含了很多磁盘上的块数据。Linux使用Radix树实现页缓存，主要是加速特定页的查找速度。另外一般使用LRU策略来淘汰过期页数据。总之它是一个完全由内核来管理的磁盘缓存，用户应用程序通常是无感知的。</li>
<li>如果要详细了解page cache，可以参见《Understanding the Linux Kernel》一书的第15章</li>
</ul>
<ol start="56">
<li>kafka streams或者ksql的性能参数调优有什么建议和参考资料吗？</li>
</ol>
<ul>
<li>Kafka Streams的性能调优建议：<a target="_blank" rel="noopener" href="https://www.confluent.io/blog/optimizing-kafka-streams-applications">https://www.confluent.io/blog/optimizing-kafka-streams-applications</a></li>
</ul>
<ol start="57">
<li><p>虽然无脑推荐6GB，但绝不是无脑推荐&gt;6GB。一个16GB的堆Full GC一次要花多长时间啊，所以我觉得6GB可以是一个初始值，你可以实时监控堆上的live data大小，根据这个值调整heap size。只是因为大内存就直接调整到16GB，个人觉得不可取。另外堆越小留给页缓存的空间也就越大，这对Kafka是好事啊。</p>
</li>
<li><p>，kafka认为写入成功是指写入页缓存成功还是数据刷到磁盘成功算成功呢？还是上次刷盘宕机失败的问题，页缓存的数据如果刷盘失败，是不是就丢了？这个异常会不会响应给生产者让其重发呢？</p>
</li>
</ol>
<ul>
<li>写入到页缓存即认为成功。如果在flush之前机器就宕机了，的确这条数据在broker上就算丢失了。</li>
<li>producer端表现如何取决于acks的设定。如果是acks=1而恰恰是leader broker在flush前宕机，那么的确有可能消息就丢失了，而且producer端不会重发——因为它认为是成功了。</li>
</ul>
<ol start="59">
<li><p>修改 Topic 级 max.message.bytes，还要考虑以下两个吧？还要修改 Broker的 replica.fetch.max.bytes 保证复制正常;消费还要修改配置 fetch.message.max.bytes</p>
</li>
<li><p>G1是jdk9中默认的，jdk8还是需要显式指定的</p>
</li>
</ol>
</section>
    <!-- Tags START -->
    
      <div class="tags">
        <span>Tags:</span>
        
  <a href="/tags#kafka" >
    <span class="tag-code">kafka</span>
  </a>

      </div>
    
    <!-- Tags END -->
    <!-- NAV START -->
    
  <div class="nav-container">
    <!-- reverse left and right to put prev and next in a more logic postition -->
    
      <a class="nav-left" href="/2021/05/23/kafka%E7%B3%BB%E5%88%97-%E9%9B%86%E7%BE%A4%E5%8F%82%E6%95%B0%E9%85%8D%E7%BD%AE/">
        <span class="nav-arrow">← </span>
        
          kafka系列 | 集群参数配置
        
      </a>
    
    
      <a class="nav-right" href="/2021/05/24/docker-%E5%85%B1%E4%BA%AB%E5%AE%BF%E4%B8%BB%E6%9C%BA%E7%8E%AF%E5%A2%83/">
        
          docker | 共享宿主机环境
        
        <span class="nav-arrow"> →</span>
      </a>
    
  </div>

    <!-- NAV END -->
    <!-- 打赏 START -->
    
    <!-- 打赏 END -->
    <!-- 二维码 START -->
    
      <div class="qrcode">
        <canvas id="share-qrcode"></canvas>
        <p class="notice">扫描二维码，分享此文章</p>
      </div>
    
    <!-- 二维码 END -->
    
      <!-- Gitment START -->
      <div id="comments"></div>
      <!-- Gitment END -->
    
  </article>
  <!-- Article END -->
  <!-- Catalog START -->
  
    <aside class="catalog-container">
  <div class="toc-main">
    <strong class="toc-title">目录</strong>
    
      <ol class="nav">none</ol>
    
  </div>
</aside>
  
  <!-- Catalog END -->
</main>

<script>
  (function () {
    var url = 'http://chenrongquan.github.com/2021/05/23/kafka系列-常见问题解答4/';
    var banner = ''
    if (banner !== '' && banner !== 'undefined' && banner !== 'null') {
      $('#article-banner').css({
        'background-image': 'url(' + banner + ')'
      })
    } else {
      $('#article-banner').geopattern(url)
    }
    $('.header').removeClass('fixed-header')

    // error image
    $(".markdown-content img").on('error', function() {
      $(this).attr('src', 'http://file.muyutech.com/error-img.png')
      $(this).css({
        'cursor': 'default'
      })
    })

    // zoom image
    $(".markdown-content img").on('click', function() {
      var src = $(this).attr('src')
      if (src !== 'http://file.muyutech.com/error-img.png') {
        var imageW = $(this).width()
        var imageH = $(this).height()

        var zoom = ($(window).width() * 0.95 / imageW).toFixed(2)
        zoom = zoom < 1 ? 1 : zoom
        zoom = zoom > 2 ? 2 : zoom
        var transY = (($(window).height() - imageH) / 2).toFixed(2)

        $('body').append('<div class="image-view-wrap"><div class="image-view-inner"><img src="'+ src +'" /></div></div>')
        $('.image-view-wrap').addClass('wrap-active')
        $('.image-view-wrap img').css({
          'width': `${imageW}`,
          'transform': `translate3d(0, ${transY}px, 0) scale3d(${zoom}, ${zoom}, 1)`
        })
        $('html').css('overflow', 'hidden')

        $('.image-view-wrap').on('click', function() {
          $(this).remove()
          $('html').attr('style', '')
        })
      }
    })
  })();
</script>


  <script>
    // qrcode
    var qr = new QRious({
      element: document.getElementById('share-qrcode'),
      value: document.location.href
    });
  </script>



  <script>
    // gitment
    var gitmentConfig = "chenrongquan";
    if (gitmentConfig !== 'undefined') {
      var gitment = new Gitment({
        id: "kafka系列 | 常见问题解答(4)",
        owner: "chenrongquan",
        repo: "chenrongquan.github.io",
        oauth: {
          client_id: "f1711d39536b30d7ad8b",
          client_secret: "a1359714a0061235611e2e06302572ac0b40a17f"
        },
        theme: {
          render(state, instance) {
            const container = document.createElement('div')
            container.lang = "en-US"
            container.className = 'gitment-container gitment-root-container'
            container.appendChild(instance.renderHeader(state, instance))
            container.appendChild(instance.renderEditor(state, instance))
            container.appendChild(instance.renderComments(state, instance))
            container.appendChild(instance.renderFooter(state, instance))
            return container;
          }
        }
      })
      gitment.render(document.getElementById('comments'))
    }
  </script>




    <div class="scroll-top">
  <span class="arrow-icon"></span>
</div>
    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<footer class="app-footer">
    <p class="copyright">
      &copy; 2021 | powered by <a href="https://github.com/chenrongquan/chenrongquan.github.io" target="_blank">chenrongquan</a>
    </p>
    <p id="busuanzi_container_site_pv">
      本站总访问量<span id="busuanzi_value_site_pv"></span>次 &nbsp;&nbsp;
    </p>
    <p id="busuanzi_container_page_pv">
      本文总阅读量<span id="busuanzi_value_page_pv"></span>次
    </p>
</footer>

<script>
  function async(u, c) {
    var d = document, t = 'script',
      o = d.createElement(t),
      s = d.getElementsByTagName(t)[0];
    o.src = u;
    if (c) { 
      o.addEventListener('load', function (e) { c(null, e); }, false); }
    s.parentNode.insertBefore(o, s);
  }
</script>
<script>
  async("//cdn.bootcss.com/fastclick/1.0.6/fastclick.min.js", function () {
    FastClick.attach(document.body);
  })
</script>

<script>
  var hasLine = 'true';
  async("//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js", function(){
    $('figure pre').each(function(i, block) {
      var figure = $(this).parents('figure');
      if (hasLine === 'false') {
        figure.find('.gutter').hide();
      }
      var lang = figure.attr('class').split(' ')[1] || 'code';
      var codeHtml = $(this).html();
      var codeTag = document.createElement('code');
      codeTag.className = lang;
      codeTag.innerHTML = codeHtml;
      $(this).attr('class', '').empty().html(codeTag);
      figure.attr('data-lang', lang.toUpperCase());
      hljs.highlightBlock(block);
    });
  })
</script>
<!-- Baidu Tongji -->


<script src="/js/script.js"></script>

  </body>
</html>